import os
import time
import streamlit as st
from datetime import datetime
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
doc_dir = "docs"
last_update_file = "last_update.txt"
db_file = "vectordb_index"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ“š ë¬¸ì„œ ê¸°ë°˜ GPT ì±—ë´‡", layout="wide")
st.title("ğŸ“š ë¡œì»¬ ë¬¸ì„œ ê¸°ë°˜ GPT ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "ready" not in st.session_state:
    st.session_state["ready"] = False
if "vectordb" not in st.session_state:
    st.session_state["vectordb"] = None
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
if "model_name" not in st.session_state:
    st.session_state["model_name"] = "gpt-3.5-turbo"

# ëª¨ë¸ ì„ íƒ
model_name = st.selectbox("ğŸ¤– ì‚¬ìš©í•  GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", ["gpt-3.5-turbo", "gpt-4o"], index=0)
st.session_state["model_name"] = model_name

# ë¬¸ì„œ ë³€ê²½ ì—¬ë¶€ í™•ì¸
need_reload = False
latest_mtime = 0
modified_files = []

for file in os.listdir(doc_dir):
    if file.endswith(".pdf"):
        path = os.path.join(doc_dir, file)
        mtime = os.path.getmtime(path)
        if mtime > latest_mtime:
            latest_mtime = mtime
        modified_files.append((file, mtime))

last_saved_time = 0
if os.path.exists(last_update_file):
    with open(last_update_file, "r") as f:
        last_saved_time = float(f.read())

if latest_mtime > last_saved_time:
    need_reload = True

# ë²¡í„° DB ì´ˆê¸°í™” ë° ë¡œë”©
if need_reload or not os.path.exists(last_update_file):
    with st.spinner("ğŸ“ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        all_docs = []
        for file in os.listdir(doc_dir):
            if file.endswith(".pdf"):
                path = os.path.join(doc_dir, file)
                loader = PyPDFLoader(path)
                all_docs.extend(loader.load())

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        split_docs = splitter.split_documents(all_docs)
        vectordb = FAISS.from_documents(split_docs, OpenAIEmbeddings(openai_api_key=api_key))
        st.session_state["vectordb"] = vectordb

        with open(last_update_file, "w") as f:
            f.write(str(time.time()))

        st.session_state["ready"] = True

        # ë³€ê²½ëœ íŒŒì¼ë§Œ í‘œì‹œ
        if need_reload:
            st.subheader("ğŸ“„ ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ ëª©ë¡")
            for name, ts in modified_files:
                if ts > last_saved_time:
                    download_link = os.path.join(doc_dir, name)
                    st.markdown(f"- [{name}]({download_link}) (ìˆ˜ì •: {datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')})")
else:
    if not st.session_state["vectordb"]:
        all_docs = []
        for file in os.listdir(doc_dir):
            if file.endswith(".pdf"):
                path = os.path.join(doc_dir, file)
                loader = PyPDFLoader(path)
                all_docs.extend(loader.load())

        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        split_docs = splitter.split_documents(all_docs)
        vectordb = FAISS.from_documents(split_docs, OpenAIEmbeddings(openai_api_key=api_key))
        st.session_state["vectordb"] = vectordb
        st.session_state["ready"] = True

# ë¬¸ì„œ ë¡œë”© ìƒíƒœ í‘œì‹œ
if st.session_state["ready"]:
    st.success("âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ! ì§€ê¸ˆ ë°”ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
else:
    st.warning("â³ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶œë ¥
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
if st.session_state["ready"]:
    user_input = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
else:
    st.chat_input("â³ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì…ë ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤)", disabled=True)
    user_input = None

# ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
if user_input and st.session_state["ready"]:
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– GPTê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤..."):
            docs_and_scores = st.session_state["vectordb"].similarity_search_with_score(user_input, k=5)
            docs = [doc for doc, score in docs_and_scores if score > 0.3]

            system_prompt = f"""
            ë„ˆëŠ” ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì•¼.
            ì•„ë˜ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ í•œêµ­ì–´ë¡œ ìì„¸íˆ ì„¤ëª…í•´ì¤˜.
            ë¬¸ì„œê°€ ì˜ì–´ë¡œ ë˜ì–´ ìˆì–´ë„ ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´.
            ê·¸ë¦¬ê³  í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•´ë„ ë¬¸ì„œë“¤ì´ ì˜ì–´ì¼ ê²½ìš° ë‹µë³€ì´ ì•ˆë  ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•´ë„ í•œë²ˆ ì˜ì–´ë¡œ ë³€ê²½í•´ì„œ ë‹µë³€ì„ ì°¾ì•„ë´ì¤˜.
            ì§ˆë¬¸: {user_input}
            """

            llm = ChatOpenAI(
                model_name=st.session_state["model_name"],
                temperature=0,
                openai_api_key=api_key,
                base_url="https://oai.hconeai.com/v1",  # Helicone í”„ë¡ì‹œ ì£¼ì†Œ
                default_headers={
                    "Helicone-Auth": f"Bearer {os.getenv('HELICONE_API_KEY')}"
                }
            )

    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.chat_history.append({"role": "assistant", "content": response})
