import os
import time
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain_openai import ChatOpenAI

# Load environment variables
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
doc_dir = "docs"
last_update_file = "last_update.txt"

st.set_page_config(page_title="ğŸ“š ë¬¸ì„œ ê¸°ë°˜ GPT ì±—ë´‡", layout="wide")
st.title("ğŸ“š ë¡œì»¬ ë¬¸ì„œ ê¸°ë°˜ GPT ì±—ë´‡")

# âœ… ë¬¸ì„œ ì¤€ë¹„ ìƒíƒœ í‘œì‹œ
if "ready" not in st.session_state:
    st.session_state["ready"] = False
if "vectordb" not in st.session_state:
    st.session_state["vectordb"] = None
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
if "model_name" not in st.session_state:
    st.session_state["model_name"] = "gpt-3.5-turbo"

# ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´
model_name = st.selectbox("ğŸ¤– ì‚¬ìš©í•  GPT ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", ["gpt-3.5-turbo", "gpt-4o"], index=0)
st.session_state["model_name"] = model_name

if st.session_state["ready"]:
    st.success("âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ! ì§€ê¸ˆ ë°”ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
else:
    st.warning("â³ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")

# ë¬¸ì„œ ìë™ ì—…ë°ì´íŠ¸ ë° ë¡œë”© í•¨ìˆ˜
def load_documents():
    with st.spinner("ğŸ“ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        all_docs = []
        updated_files = []
        last_time = 0
        if os.path.exists(last_update_file):
            with open(last_update_file, "r") as f:
                last_time = float(f.read())

        for file in os.listdir(doc_dir):
            if file.endswith(".pdf"):
                path = os.path.join(doc_dir, file)
                if os.path.getmtime(path) > last_time:
                    loader = PyPDFLoader(path)
                    all_docs.extend(loader.load())
                    updated_files.append(file)

        if all_docs:
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            split_docs = splitter.split_documents(all_docs)
            vectordb = FAISS.from_documents(split_docs, OpenAIEmbeddings(openai_api_key=api_key))
            st.session_state["vectordb"] = vectordb
            st.success(f"ğŸ”„ {len(updated_files)}ê°œì˜ ë¬¸ì„œë¥¼ ìƒˆë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        else:
            st.info("âœ… ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œê°€ ì—†ì–´ ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        with open(last_update_file, "w") as f:
            f.write(str(time.time()))

        st.session_state["ready"] = True

# ìµœì´ˆ ì‹¤í–‰ ì‹œ ë¬¸ì„œ ìë™ ë¡œë“œ
if not st.session_state["ready"]:
    load_documents()

# ëŒ€í™” UI ì¶œë ¥
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ì°½ (ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ ì—¬ë¶€ì— ë”°ë¼ í™œì„±/ë¹„í™œì„±)
if st.session_state["ready"]:
    user_input = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
else:
    st.chat_input("â³ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì…ë ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤)", disabled=True)
    user_input = None

if user_input and st.session_state["ready"]:
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– GPTê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤..."):
            docs = st.session_state["vectordb"].similarity_search(user_input, k=5)
            llm = ChatOpenAI(model_name=st.session_state["model_name"], temperature=0, openai_api_key=api_key)
            chain = load_qa_chain(llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=user_input)
            st.markdown(response)

    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.chat_history.append({"role": "assistant", "content": response})
