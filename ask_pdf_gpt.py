import os
from langchain.document_loaders import PyPDFLoader
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import CharacterTextSplitter
import getpass

# GPT API Key ì…ë ¥ ë°›ê¸° (ì²˜ìŒ 1íšŒë§Œ)
openai_api_key = input("OpenAI API Key ì…ë ¥ (ë³µë¶™ ê°€ëŠ¥): ")

# 1. PDF ê²½ë¡œ ì„¤ì •
pdf_dir = "D:/toyproj"
all_docs = []

# 2. PDF íŒŒì¼ ë¡œë“œ ë° ë¶„í• 
print("ğŸ“„ PDF ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
for filename in os.listdir(pdf_dir):
    if filename.endswith(".pdf"):
        loader = PyPDFLoader(os.path.join(pdf_dir, filename))
        docs = loader.load()
        all_docs.extend(docs)

# 3. í…ìŠ¤íŠ¸ ë¶„í• 
print("ğŸ” ë¬¸ì„œ ë¶„í•  ë° ì„ë² ë”© ì¤‘...")
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
split_docs = text_splitter.split_documents(all_docs)

# 4. Chroma ë²¡í„° DB ìƒì„±
db = Chroma.from_documents(split_docs, OpenAIEmbeddings(openai_api_key=openai_api_key))

# 5. ì§ˆì˜ ì‘ë‹µ ì²´ì¸ ìƒì„±
qa = RetrievalQA.from_chain_type(
    llm=OpenAI(openai_api_key=openai_api_key),
    retriever=db.as_retriever(),
    return_source_documents=True
)

# 6. ì§ˆë¬¸ ë£¨í”„
print("\nâœ… ì„¤ì • ì™„ë£Œ! PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit')")
while True:
    query = input("\nì§ˆë¬¸: ")
    if query.lower() in ["exit", "quit"]:
        break

    result = qa({"query": query})
    print("\nğŸ“Œ ë‹µë³€:")
    print(result["result"])

    print("\nğŸ” ì¶œì²˜ ë¬¸ì„œ ì¼ë¶€:")
    for doc in result["source_documents"]:
        print(f"â†’ {doc.metadata['source']}")
