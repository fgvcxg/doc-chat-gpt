import os
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import FakeEmbeddings

# 1. ë¬¸ì„œ ë¡œë”©
pdf_dir = "D:/toyproj"
all_docs = []

print("ğŸ“„ PDF ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
for filename in os.listdir(pdf_dir):
    if filename.endswith(".pdf"):
        loader = PyPDFLoader(os.path.join(pdf_dir, filename))
        docs = loader.load()
        all_docs.extend(docs)

# 2. í…ìŠ¤íŠ¸ ë¶„í• 
splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
split_docs = splitter.split_documents(all_docs)

# 3. ë²¡í„° DBì— ì €ì¥ (FakeEmbeddings ì‚¬ìš©)
print("ğŸ” ë²¡í„° ì¸ë±ì‹± ì¤‘... (GPT ì—†ì´ ì‘ë™)")
embedding = FakeEmbeddings(size=768)  # ì‹¤ì œ ì„ë² ë”©ì€ í•˜ì§€ ì•Šì§€ë§Œ êµ¬ì¡°ë§Œ ìœ ì§€
db = Chroma.from_documents(split_docs, embedding)

retriever = db.as_retriever()

# 4. ê²€ìƒ‰ ë£¨í”„ ì‹œì‘
print("\nâœ… ì„¤ì • ì™„ë£Œ! PDF ë¬¸ì„œ ë‚´ìš© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit')")
while True:
    query = input("\nì§ˆë¬¸ í‚¤ì›Œë“œ: ")
    if query.lower() in ["exit", "quit"]:
        break

    results = retriever.get_relevant_documents(query)
    
    if not results:
        print("âŒ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"\nğŸ” ê´€ë ¨ëœ ë¬¸ì„œ ì¡°ê° {len(results)}ê°œ:")
        for i, doc in enumerate(results):
            print(f"\n--- ë¬¸ì„œ {i+1} ---")
            print(doc.page_content.strip()[:500] + "...")
